{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyexpat import model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import locale\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import preprocessing\n",
    "import locale\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from deepforest import CascadeForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tensorflow.keras.layers import DepthwiseConv2D\n",
    "from tensorflow.keras.layers import ReLU, AvgPool2D\n",
    "# from tensorflow.keras.layers import Input, DepthwiseConv2D\n",
    "# from tensorflow.keras.layers import Conv2D, BatchNormalization\n",
    "# from tensorflow.keras.layers import ReLU, AvgPool2D, Flatten, Dense\n",
    "# from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "(1000, 320, 320, 9)\n"
     ]
    }
   ],
   "source": [
    "gasdata = pd.read_csv(\"/Users/Eddie/Downloads/data5.csv\")\n",
    "data_dir = '/Users/Eddie/Downloads/Data5'\n",
    "imagedata = sorted(os.listdir(data_dir))\n",
    "print(len(imagedata))\n",
    "X_data = []\n",
    "for image in imagedata:\n",
    "        # print(image)\n",
    "        img = mpimg.imread('/Users/Eddie/Downloads/Data5/'+image)\n",
    "        img = img.reshape(320,320,9)\n",
    "        img = img/255.0\n",
    "        X_data.append(img)\n",
    "images = np.array(X_data)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2)\n",
      "(200, 2)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "split = train_test_split(gasdata, images, test_size=0.2)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
    "trainy = trainAttrX[\"Gas\"]\n",
    "testy = testAttrX[\"Gas\"]\n",
    "trainAttrX = trainAttrX.drop(columns=['Gas'])\n",
    "testAttrX = testAttrX.drop(columns = ['Gas'])\n",
    "trainAttrX= (trainAttrX - np.min(trainAttrX)) / (np.max(trainAttrX) - np.min(trainAttrX))\n",
    "testAttrX = (testAttrX - np.min(testAttrX)) / (np.max(testAttrX) - np.min(testAttrX))\n",
    "print(trainAttrX.shape)\n",
    "print(testAttrX.shape)\n",
    "print(trainy.shape)\n",
    "print(testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_alexnet():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 96, input_shape = (320, 320, 9),  \n",
    "                kernel_size = (11, 11), strides = (4, 4),  \n",
    "                padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling  \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), \n",
    "                strides = (2, 2), padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 2nd Convolutional Layer \n",
    "    model.add(Conv2D(filters = 256, kernel_size = (11, 11),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),  \n",
    "                padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 3rd Convolutional Layer \n",
    "    model.add(Conv2D(filters = 384, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 4th Convolutional Layer \n",
    "    model.add(Conv2D(filters = 384, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 5th Convolutional Layer \n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),  \n",
    "                padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # Flattening \n",
    "    model.add(Flatten()) \n",
    "    \n",
    "    # 1st Dense Layer \n",
    "    model.add(Dense(4096, input_shape = (224*224*3, ))) \n",
    "    model.add(Activation('relu')) \n",
    "    # Add Dropout to prevent overfitting \n",
    "    model.add(Dropout(0.4)) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 2nd Dense Layer \n",
    "    model.add(Dense(4096)) \n",
    "    model.add(Activation('relu')) \n",
    "    # Add Dropout \n",
    "    model.add(Dropout(0.4)) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_resnet():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,input_shape = (320,320,9), kernel_size = (7,7), strides = 2, padding = 'valid', activation = 'relu'))\n",
    "    model.add(AveragePooling2D(pool_size = 2))\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D(pool_size = 2, padding = 'same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet block\n",
    "def mobilnet_block (x, filters, strides):\n",
    "    \n",
    "    x = DepthwiseConv2D(kernel_size = 3, strides = strides, padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters = filters, kernel_size = 1, strides = 1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def create_cnn_mobilenet():\n",
    "    input = Input(shape = (320,320,9))\n",
    "    x = Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # main part of the model\n",
    "    x = mobilnet_block(x, filters = 64, strides = 1)\n",
    "    x = mobilnet_block(x, filters = 128, strides = 2)\n",
    "    x = mobilnet_block(x, filters = 128, strides = 1)\n",
    "    x = mobilnet_block(x, filters = 256, strides = 2)\n",
    "    x = mobilnet_block(x, filters = 256, strides = 1)\n",
    "    x = mobilnet_block(x, filters = 512, strides = 2)\n",
    "    for _ in range (5):\n",
    "        x = mobilnet_block(x, filters = 512, strides = 1)\n",
    "    x = mobilnet_block(x, filters = 1024, strides = 2)\n",
    "    x = mobilnet_block(x, filters = 1024, strides = 1)\n",
    "    x = AvgPool2D (pool_size = 7, strides = 1, data_format='channels_first')(x)\n",
    "   # output = Dense (units = 1000, activation = 'softmax')(x)\n",
    "    output = Flatten()(x)\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    # model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "25/25 [==============================] - 14s 542ms/step\n",
      "(800, 4096)\n"
     ]
    }
   ],
   "source": [
    "alexnet = create_cnn_alexnet()\n",
    "alexnetPredict = alexnet.predict(trainImagesX)\n",
    "print(alexnetPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 25s 938ms/step\n",
      "(800, 2048)\n"
     ]
    }
   ],
   "source": [
    "resnet = create_cnn_resnet()\n",
    "resnetPredict = resnet.predict(trainImagesX)\n",
    "print(resnetPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 13s 484ms/step\n",
      "(800, 40720)\n"
     ]
    }
   ],
   "source": [
    "mobilenet = create_cnn_mobilenet()\n",
    "mobilenetPredict = mobilenet.predict(trainImagesX)\n",
    "print(mobilenetPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 46866)\n"
     ]
    }
   ],
   "source": [
    "alexnetPredict = np.array(alexnetPredict)\n",
    "resnetPredict = np.array(resnetPredict)\n",
    "mobilenetPredict = np.array(mobilenetPredict)\n",
    "trainAttrX = np.array(trainAttrX)\n",
    "trainAttrX.resize(800,2)\n",
    "trainData = concatenate([alexnetPredict,resnetPredict,mobilenetPredict,trainAttrX])\n",
    "trainData = np.array(trainData)\n",
    "trainData.reshape(-1,1)\n",
    "\n",
    "print(trainData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-17 21:32:21.023] Start to fit the model:\n",
      "[2023-12-17 21:32:21.023] Fitting cascade layer = 0 \n",
      "[2023-12-17 21:48:44.859] layer = 0  | Val Acc = 98.625 % | Elapsed = 983.836 s\n",
      "[2023-12-17 21:48:45.073] Fitting cascade layer = 1 \n",
      "[2023-12-17 21:52:54.635] layer = 1  | Val Acc = 98.750 % | Elapsed = 249.561 s\n",
      "[2023-12-17 21:52:54.646] Fitting cascade layer = 2 \n",
      "[2023-12-17 21:56:46.808] layer = 2  | Val Acc = 98.875 % | Elapsed = 232.162 s\n",
      "[2023-12-17 21:56:46.824] Fitting cascade layer = 3 \n",
      "[2023-12-17 22:00:39.463] layer = 3  | Val Acc = 99.000 % | Elapsed = 232.639 s\n",
      "[2023-12-17 22:00:39.471] Fitting cascade layer = 4 \n",
      "[2023-12-17 22:04:42.423] layer = 4  | Val Acc = 98.875 % | Elapsed = 242.952 s\n",
      "[2023-12-17 22:04:42.423] Early stopping counter: 1 out of 2\n",
      "[2023-12-17 22:04:42.439] Fitting cascade layer = 5 \n",
      "[2023-12-17 22:08:51.938] layer = 5  | Val Acc = 98.875 % | Elapsed = 249.499 s\n",
      "[2023-12-17 22:08:51.938] Early stopping counter: 2 out of 2\n",
      "[2023-12-17 22:08:51.938] Handling early stopping\n",
      "[2023-12-17 22:08:51.948] The optimal number of layers: 4\n"
     ]
    }
   ],
   "source": [
    "model = CascadeForestClassifier(n_estimators=50,random_state=1)\n",
    "model.fit(trainData,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 446ms/step\n",
      "7/7 [==============================] - 7s 842ms/step\n",
      "7/7 [==============================] - 3s 416ms/step\n",
      "(200, 4096)\n",
      "(200, 2048)\n",
      "(200, 40720)\n",
      "(200, 2)\n",
      "(200, 46866)\n"
     ]
    }
   ],
   "source": [
    "# savemodel\n",
    "# testAttrX\n",
    "# testImagesX\n",
    "\n",
    "alexnetPredictTest = np.array(alexnet.predict(testImagesX))\n",
    "resnetPredictTest = np.array(resnet.predict(testImagesX))\n",
    "mobilenetPredictTest = np.array(mobilenet.predict(testImagesX))\n",
    "testAttrX = np.array(testAttrX)\n",
    "print(alexnetPredictTest.shape)\n",
    "print(resnetPredictTest.shape)\n",
    "print(mobilenetPredictTest.shape)\n",
    "print(testAttrX.shape)\n",
    "\n",
    "testData = concatenate([alexnetPredictTest, resnetPredictTest, mobilenetPredictTest, testAttrX])\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-17 22:10:28.147] Start to evalute the model:\n",
      "[2023-12-17 22:10:28.557] Evaluating cascade layer = 0 \n",
      "[2023-12-17 22:10:28.969] Evaluating cascade layer = 1 \n",
      "[2023-12-17 22:10:29.242] Evaluating cascade layer = 2 \n",
      "[2023-12-17 22:10:29.486] Evaluating cascade layer = 3 \n",
      "Precision: 1.000000\n",
      "Recall: 1.000000\n",
      "F1 score: 1.000000\n"
     ]
    }
   ],
   "source": [
    "performance = model.predict(testData)\n",
    "performance.round()\n",
    "actual = []\n",
    "for value in performance: \n",
    "    # print(value)\n",
    "    if(value>=0.5):\n",
    "            actual.append(1)\n",
    "    else:\n",
    "            actual.append(0)\n",
    "\n",
    "acutal = np.array(actual)\n",
    "# print(actual)\n",
    "# print(testy)\n",
    "precision = precision_score(testy, actual)\n",
    "print('Precision: %f' % precision)\n",
    "recall = recall_score(testy, actual)\n",
    "print('Recall: %f' % recall)\n",
    "f1 = f1_score(testy, actual)\n",
    "print('F1 score: %f' % f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
