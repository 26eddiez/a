{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyexpat import model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import locale\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import preprocessing\n",
    "import locale\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from deepforest import CascadeForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "(1000, 320, 320, 9)\n"
     ]
    }
   ],
   "source": [
    "gasdata = pd.read_csv(\"/Users/Eddie/Downloads/data5.csv\")\n",
    "data_dir = '/Users/Eddie/Downloads/Data5'\n",
    "imagedata = sorted(os.listdir(data_dir))\n",
    "print(len(imagedata))\n",
    "X_data = []\n",
    "for image in imagedata:\n",
    "        # print(image)\n",
    "        img = mpimg.imread('/Users/Eddie/Downloads/Data5/'+image)\n",
    "        img = img.reshape(320,320,9)\n",
    "        img = img/255.0\n",
    "        X_data.append(img)\n",
    "images = np.array(X_data)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2)\n",
      "(200, 2)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "split = train_test_split(gasdata, images, test_size=0.2)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
    "trainy = trainAttrX[\"Gas\"]\n",
    "testy = testAttrX[\"Gas\"]\n",
    "trainAttrX = trainAttrX.drop(columns=['Gas'])\n",
    "testAttrX = testAttrX.drop(columns = ['Gas'])\n",
    "trainAttrX= (trainAttrX - np.min(trainAttrX)) / (np.max(trainAttrX) - np.min(trainAttrX))\n",
    "testAttrX = (testAttrX - np.min(testAttrX)) / (np.max(testAttrX) - np.min(testAttrX))\n",
    "print(trainAttrX.shape)\n",
    "print(testAttrX.shape)\n",
    "print(trainy.shape)\n",
    "print(testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_alexnet():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 96, input_shape = (320, 320, 9),  \n",
    "                kernel_size = (11, 11), strides = (4, 4),  \n",
    "                padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling  \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), \n",
    "                strides = (2, 2), padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 2nd Convolutional Layer \n",
    "    model.add(Conv2D(filters = 256, kernel_size = (11, 11),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),  \n",
    "                padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 3rd Convolutional Layer \n",
    "    model.add(Conv2D(filters = 384, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 4th Convolutional Layer \n",
    "    model.add(Conv2D(filters = 384, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 5th Convolutional Layer \n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),  \n",
    "                padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # Flattening \n",
    "    model.add(Flatten()) \n",
    "    \n",
    "    # 1st Dense Layer \n",
    "    model.add(Dense(4096, input_shape = (224*224*3, ))) \n",
    "    model.add(Activation('relu')) \n",
    "    # Add Dropout to prevent overfitting \n",
    "    model.add(Dropout(0.4)) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 2nd Dense Layer \n",
    "    model.add(Dense(4096)) \n",
    "    model.add(Activation('relu')) \n",
    "    # Add Dropout \n",
    "    model.add(Dropout(0.4)) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_resnet():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,input_shape = (320,320,9), kernel_size = (7,7), strides = 2, padding = 'valid', activation = 'relu'))\n",
    "    model.add(AveragePooling2D(pool_size = 2))\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D(pool_size = 2, padding = 'same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "25/25 [==============================] - 14s 540ms/step\n",
      "(800, 4096)\n"
     ]
    }
   ],
   "source": [
    "alexnet = create_cnn_alexnet()\n",
    "alexnetPredict = alexnet.predict(trainImagesX)\n",
    "print(alexnetPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 25s 951ms/step\n",
      "(800, 2048)\n"
     ]
    }
   ],
   "source": [
    "resnet = create_cnn_resnet()\n",
    "resnetPredict = resnet.predict(trainImagesX)\n",
    "print(resnetPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 6146)\n"
     ]
    }
   ],
   "source": [
    "alexnetPredict = np.array(alexnetPredict)\n",
    "resnetPredict = np.array(resnetPredict)\n",
    "trainAttrX = np.array(trainAttrX)\n",
    "trainAttrX.resize(800,2)\n",
    "trainData = concatenate([alexnetPredict,resnetPredict,trainAttrX])\n",
    "trainData = np.array(trainData)\n",
    "trainData.reshape(-1,1)\n",
    "\n",
    "print(trainData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-17 02:27:21.847] Start to fit the model:\n",
      "[2023-12-17 02:27:21.847] Fitting cascade layer = 0 \n",
      "[2023-12-17 02:29:41.789] layer = 0  | Val Acc = 98.250 % | Elapsed = 139.942 s\n",
      "[2023-12-17 02:29:41.940] Fitting cascade layer = 1 \n",
      "[2023-12-17 02:30:22.455] layer = 1  | Val Acc = 99.125 % | Elapsed = 40.515 s\n",
      "[2023-12-17 02:30:22.472] Fitting cascade layer = 2 \n",
      "[2023-12-17 02:30:58.909] layer = 2  | Val Acc = 99.250 % | Elapsed = 36.437 s\n",
      "[2023-12-17 02:30:58.922] Fitting cascade layer = 3 \n",
      "[2023-12-17 02:31:36.655] layer = 3  | Val Acc = 99.250 % | Elapsed = 37.733 s\n",
      "[2023-12-17 02:31:36.655] Early stopping counter: 1 out of 2\n",
      "[2023-12-17 02:31:36.665] Fitting cascade layer = 4 \n",
      "[2023-12-17 02:32:16.242] layer = 4  | Val Acc = 99.000 % | Elapsed = 39.577 s\n",
      "[2023-12-17 02:32:16.242] Early stopping counter: 2 out of 2\n",
      "[2023-12-17 02:32:16.242] Handling early stopping\n",
      "[2023-12-17 02:32:16.249] The optimal number of layers: 3\n"
     ]
    }
   ],
   "source": [
    "model = CascadeForestClassifier(n_estimators=50,random_state=1)\n",
    "model.fit(trainData,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 441ms/step\n",
      "7/7 [==============================] - 6s 823ms/step\n",
      "(200, 4096)\n",
      "(200, 2048)\n",
      "(200, 2)\n",
      "(200, 6146)\n"
     ]
    }
   ],
   "source": [
    "# savemodel\n",
    "# testAttrX\n",
    "# testImagesX\n",
    "\n",
    "alexnetPredictTest = np.array(alexnet.predict(testImagesX))\n",
    "resnetPredictTest = np.array(resnet.predict(testImagesX))\n",
    "testAttrX = np.array(testAttrX)\n",
    "print(alexnetPredictTest.shape)\n",
    "print(resnetPredictTest.shape)\n",
    "print(testAttrX.shape)\n",
    "\n",
    "testData = concatenate([alexnetPredictTest, resnetPredictTest, testAttrX])\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-17 02:35:37.468] Start to evalute the model:\n",
      "[2023-12-17 02:35:37.515] Evaluating cascade layer = 0 \n",
      "[2023-12-17 02:35:37.823] Evaluating cascade layer = 1 \n",
      "[2023-12-17 02:35:38.037] Evaluating cascade layer = 2 \n",
      "Precision: 0.979167\n",
      "Recall: 1.000000\n",
      "F1 score: 0.989474\n"
     ]
    }
   ],
   "source": [
    "performance = model.predict(testData)\n",
    "performance.round()\n",
    "actual = []\n",
    "for value in performance: \n",
    "    # print(value)\n",
    "    if(value>=0.5):\n",
    "            actual.append(1)\n",
    "    else:\n",
    "            actual.append(0)\n",
    "\n",
    "acutal = np.array(actual)\n",
    "# print(actual)\n",
    "# print(testy)\n",
    "precision = precision_score(testy, actual)\n",
    "print('Precision: %f' % precision)\n",
    "recall = recall_score(testy, actual)\n",
    "print('Recall: %f' % recall)\n",
    "f1 = f1_score(testy, actual)\n",
    "print('F1 score: %f' % f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
