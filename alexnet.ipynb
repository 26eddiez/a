{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyexpat import model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import locale\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import preprocessing\n",
    "import locale\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from deepforest import CascadeForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 96, input_shape = (320, 320, 9),  \n",
    "                kernel_size = (11, 11), strides = (4, 4),  \n",
    "                padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling  \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), \n",
    "                strides = (2, 2), padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 2nd Convolutional Layer \n",
    "    model.add(Conv2D(filters = 256, kernel_size = (11, 11),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),  \n",
    "                padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 3rd Convolutional Layer \n",
    "    model.add(Conv2D(filters = 384, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 4th Convolutional Layer \n",
    "    model.add(Conv2D(filters = 384, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 5th Convolutional Layer \n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),  \n",
    "                padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # Flattening \n",
    "    model.add(Flatten()) \n",
    "    \n",
    "    # 1st Dense Layer \n",
    "    model.add(Dense(4096, input_shape = (224*224*3, ))) \n",
    "    model.add(Activation('relu')) \n",
    "    # Add Dropout to prevent overfitting \n",
    "    model.add(Dropout(0.4)) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 2nd Dense Layer \n",
    "    model.add(Dense(4096)) \n",
    "    model.add(Activation('relu')) \n",
    "    # Add Dropout \n",
    "    model.add(Dropout(0.4)) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64,activation = 'relu'))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "(1000, 320, 320, 9)\n"
     ]
    }
   ],
   "source": [
    "gasdata = pd.read_csv(\"/Users/Eddie/Downloads/data5 (1).csv\")\n",
    "data_dir = '/Users/Eddie/Downloads/Data5'\n",
    "imagedata = sorted(os.listdir(data_dir))\n",
    "print(len(imagedata))\n",
    "X_data = []\n",
    "for image in imagedata:\n",
    "        # print(image)\n",
    "        img = mpimg.imread('/Users/Eddie/Downloads/Data5/'+image)\n",
    "        img = img.reshape(320,320,9)\n",
    "        img = img/255.0\n",
    "        X_data.append(img)\n",
    "images = np.array(X_data)\n",
    "print(images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2)\n",
      "(200, 2)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "split = train_test_split(gasdata, images, test_size=0.2)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
    "trainy = trainAttrX[\"Gas\"]\n",
    "testy = testAttrX[\"Gas\"]\n",
    "trainAttrX = trainAttrX.drop(columns=['Gas'])\n",
    "testAttrX = testAttrX.drop(columns = ['Gas'])\n",
    "trainAttrX= (trainAttrX - np.min(trainAttrX)) / (np.max(trainAttrX) - np.min(trainAttrX))\n",
    "testAttrX = (testAttrX - np.min(testAttrX)) / (np.max(testAttrX) - np.min(testAttrX))\n",
    "print(trainAttrX.shape)\n",
    "print(testAttrX.shape)\n",
    "print(trainy.shape)\n",
    "print(testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# print(testy)\n",
    "newtesty = []\n",
    "for value in testy:\n",
    "    value = float(value)\n",
    "    newtesty.append(value)\n",
    "# print(newtesty)\n",
    "newtrainy = []\n",
    "for value in trainy:\n",
    "    value = float(value)\n",
    "    newtrainy.append(value)\n",
    "\n",
    "print(newtrainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "25/25 [==============================] - 23s 745ms/step\n",
      "(800, 1)\n"
     ]
    }
   ],
   "source": [
    "cnn = create_cnn()\n",
    "X = cnn.predict(trainImagesX)\n",
    "print(X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5000095 ]\n",
      " [0.5000029 ]\n",
      " [0.5000046 ]\n",
      " [0.5000035 ]\n",
      " [0.50000477]\n",
      " [0.5000041 ]\n",
      " [0.50001436]\n",
      " [0.5000084 ]\n",
      " [0.5000064 ]\n",
      " [0.50000936]\n",
      " [0.50000316]\n",
      " [0.50000256]\n",
      " [0.5000091 ]\n",
      " [0.50001454]\n",
      " [0.5000152 ]\n",
      " [0.5000116 ]\n",
      " [0.5000097 ]\n",
      " [0.50001305]\n",
      " [0.5000185 ]\n",
      " [0.50000435]\n",
      " [0.500004  ]\n",
      " [0.50001186]\n",
      " [0.50000346]\n",
      " [0.5000087 ]\n",
      " [0.5000062 ]\n",
      " [0.5000052 ]\n",
      " [0.5000103 ]\n",
      " [0.5000071 ]\n",
      " [0.50000733]\n",
      " [0.50000304]\n",
      " [0.5000048 ]\n",
      " [0.5000132 ]\n",
      " [0.5000171 ]\n",
      " [0.5000041 ]\n",
      " [0.50000626]\n",
      " [0.5000023 ]\n",
      " [0.50000244]\n",
      " [0.5000213 ]\n",
      " [0.50000453]\n",
      " [0.5000046 ]\n",
      " [0.5000033 ]\n",
      " [0.50001186]\n",
      " [0.50001794]\n",
      " [0.5000025 ]\n",
      " [0.500011  ]\n",
      " [0.50000733]\n",
      " [0.50001645]\n",
      " [0.5000035 ]\n",
      " [0.50001365]\n",
      " [0.5000083 ]\n",
      " [0.5000082 ]\n",
      " [0.5000103 ]\n",
      " [0.5000022 ]\n",
      " [0.50000256]\n",
      " [0.50000536]\n",
      " [0.5000116 ]\n",
      " [0.5000103 ]\n",
      " [0.5000116 ]\n",
      " [0.50000775]\n",
      " [0.50001043]\n",
      " [0.500006  ]\n",
      " [0.500012  ]\n",
      " [0.5000025 ]\n",
      " [0.5000038 ]\n",
      " [0.5000133 ]\n",
      " [0.50000757]\n",
      " [0.50000495]\n",
      " [0.50001186]\n",
      " [0.5000046 ]\n",
      " [0.50000495]\n",
      " [0.5000141 ]\n",
      " [0.4999997 ]\n",
      " [0.5000105 ]\n",
      " [0.50000405]\n",
      " [0.50000423]\n",
      " [0.5000091 ]\n",
      " [0.5000187 ]\n",
      " [0.5000028 ]\n",
      " [0.5000039 ]\n",
      " [0.5000085 ]\n",
      " [0.5000061 ]\n",
      " [0.5000135 ]\n",
      " [0.50000876]\n",
      " [0.500006  ]\n",
      " [0.5000041 ]\n",
      " [0.5000193 ]\n",
      " [0.50001484]\n",
      " [0.50000435]\n",
      " [0.5000044 ]\n",
      " [0.50000674]\n",
      " [0.5000029 ]\n",
      " [0.50000423]\n",
      " [0.5000088 ]\n",
      " [0.50001   ]\n",
      " [0.5000132 ]\n",
      " [0.500004  ]\n",
      " [0.5000047 ]\n",
      " [0.4999993 ]\n",
      " [0.5000122 ]\n",
      " [0.5000116 ]\n",
      " [0.5000028 ]\n",
      " [0.50000423]\n",
      " [0.5000028 ]\n",
      " [0.5000046 ]\n",
      " [0.5000156 ]\n",
      " [0.5000011 ]\n",
      " [0.5000049 ]\n",
      " [0.50000244]\n",
      " [0.50000423]\n",
      " [0.5000028 ]\n",
      " [0.5000019 ]\n",
      " [0.5000048 ]\n",
      " [0.50000316]\n",
      " [0.50000495]\n",
      " [0.5000074 ]\n",
      " [0.50001425]\n",
      " [0.5000053 ]\n",
      " [0.50000787]\n",
      " [0.50000674]\n",
      " [0.5000108 ]\n",
      " [0.5000008 ]\n",
      " [0.5000028 ]\n",
      " [0.5000169 ]\n",
      " [0.5000035 ]\n",
      " [0.50000507]\n",
      " [0.5000064 ]\n",
      " [0.5000164 ]\n",
      " [0.5000085 ]\n",
      " [0.50000006]\n",
      " [0.5000196 ]\n",
      " [0.49999478]\n",
      " [0.4999996 ]\n",
      " [0.5000077 ]\n",
      " [0.5000114 ]\n",
      " [0.5000032 ]\n",
      " [0.5000236 ]\n",
      " [0.5000015 ]\n",
      " [0.5000067 ]\n",
      " [0.5000095 ]\n",
      " [0.50001365]\n",
      " [0.5000036 ]\n",
      " [0.5000034 ]\n",
      " [0.50001013]\n",
      " [0.50000507]\n",
      " [0.5000029 ]\n",
      " [0.50000614]\n",
      " [0.5000045 ]\n",
      " [0.5000168 ]\n",
      " [0.500004  ]\n",
      " [0.5000052 ]\n",
      " [0.5000046 ]\n",
      " [0.49999854]\n",
      " [0.5000043 ]\n",
      " [0.50000405]\n",
      " [0.5000045 ]\n",
      " [0.50000817]\n",
      " [0.5000028 ]\n",
      " [0.500003  ]\n",
      " [0.500004  ]\n",
      " [0.49999985]\n",
      " [0.49999973]\n",
      " [0.50001234]\n",
      " [0.5000035 ]\n",
      " [0.5000066 ]\n",
      " [0.500003  ]\n",
      " [0.5000085 ]\n",
      " [0.50000376]\n",
      " [0.50000614]\n",
      " [0.5000026 ]\n",
      " [0.5000071 ]\n",
      " [0.50000507]\n",
      " [0.50000376]\n",
      " [0.5000061 ]\n",
      " [0.50000995]\n",
      " [0.5000023 ]\n",
      " [0.50001496]\n",
      " [0.50000733]\n",
      " [0.50001353]\n",
      " [0.50001496]\n",
      " [0.50000525]\n",
      " [0.50001186]\n",
      " [0.5000136 ]\n",
      " [0.5000048 ]\n",
      " [0.5000158 ]\n",
      " [0.50000495]\n",
      " [0.50001186]\n",
      " [0.5000121 ]\n",
      " [0.5000035 ]\n",
      " [0.5000061 ]\n",
      " [0.5000046 ]\n",
      " [0.5000052 ]\n",
      " [0.5000171 ]\n",
      " [0.500009  ]\n",
      " [0.5000034 ]\n",
      " [0.5000028 ]\n",
      " [0.5000078 ]\n",
      " [0.500005  ]\n",
      " [0.50001925]\n",
      " [0.5000203 ]\n",
      " [0.5000038 ]\n",
      " [0.5000019 ]\n",
      " [0.50000197]\n",
      " [0.5000048 ]\n",
      " [0.50000775]\n",
      " [0.5000016 ]\n",
      " [0.50000775]\n",
      " [0.4999996 ]\n",
      " [0.5000126 ]\n",
      " [0.50000054]\n",
      " [0.5000003 ]\n",
      " [0.5000028 ]\n",
      " [0.50000554]\n",
      " [0.5000016 ]\n",
      " [0.50000995]\n",
      " [0.5000054 ]\n",
      " [0.50000507]\n",
      " [0.50000703]\n",
      " [0.500013  ]\n",
      " [0.50000405]\n",
      " [0.5000022 ]\n",
      " [0.5000029 ]\n",
      " [0.50001115]\n",
      " [0.50000066]\n",
      " [0.5000048 ]\n",
      " [0.50000674]\n",
      " [0.50000685]\n",
      " [0.5000026 ]\n",
      " [0.5000031 ]\n",
      " [0.5000039 ]\n",
      " [0.50000185]\n",
      " [0.50000316]\n",
      " [0.5000073 ]\n",
      " [0.5000152 ]\n",
      " [0.50001705]\n",
      " [0.5000046 ]\n",
      " [0.5000111 ]\n",
      " [0.50000817]\n",
      " [0.5000008 ]\n",
      " [0.50000244]\n",
      " [0.500003  ]\n",
      " [0.50001484]\n",
      " [0.50000304]\n",
      " [0.50000507]\n",
      " [0.5000035 ]\n",
      " [0.5000042 ]\n",
      " [0.5000116 ]\n",
      " [0.5000128 ]\n",
      " [0.5000075 ]\n",
      " [0.50000817]\n",
      " [0.5000118 ]\n",
      " [0.50000244]\n",
      " [0.5000069 ]\n",
      " [0.50001234]\n",
      " [0.5000068 ]\n",
      " [0.5000022 ]\n",
      " [0.5000111 ]\n",
      " [0.500007  ]\n",
      " [0.50001496]\n",
      " [0.5000028 ]\n",
      " [0.5000024 ]\n",
      " [0.50000113]\n",
      " [0.5000033 ]\n",
      " [0.50000554]\n",
      " [0.5000056 ]\n",
      " [0.49999943]\n",
      " [0.50000316]\n",
      " [0.50000936]\n",
      " [0.50000644]\n",
      " [0.49999997]\n",
      " [0.5000127 ]\n",
      " [0.5000046 ]\n",
      " [0.5000099 ]\n",
      " [0.500001  ]\n",
      " [0.5000026 ]\n",
      " [0.50000733]\n",
      " [0.5000027 ]\n",
      " [0.5000008 ]\n",
      " [0.50001186]\n",
      " [0.5000047 ]\n",
      " [0.50001043]\n",
      " [0.4999996 ]\n",
      " [0.500006  ]\n",
      " [0.5000089 ]\n",
      " [0.50000304]\n",
      " [0.5000092 ]\n",
      " [0.5000163 ]\n",
      " [0.5000014 ]\n",
      " [0.50000256]\n",
      " [0.50000733]\n",
      " [0.5000027 ]\n",
      " [0.50000566]\n",
      " [0.50000304]\n",
      " [0.5000148 ]\n",
      " [0.50000507]\n",
      " [0.5000039 ]\n",
      " [0.50000465]\n",
      " [0.5000049 ]\n",
      " [0.50001985]\n",
      " [0.5000163 ]\n",
      " [0.5000028 ]\n",
      " [0.5000008 ]\n",
      " [0.5000039 ]\n",
      " [0.50000006]\n",
      " [0.50000685]\n",
      " [0.5000109 ]\n",
      " [0.5000071 ]\n",
      " [0.50000316]\n",
      " [0.500005  ]\n",
      " [0.5000027 ]\n",
      " [0.5000162 ]\n",
      " [0.500011  ]\n",
      " [0.5000089 ]\n",
      " [0.5000028 ]\n",
      " [0.50001186]\n",
      " [0.50001115]\n",
      " [0.5000034 ]\n",
      " [0.49999776]\n",
      " [0.50000006]\n",
      " [0.50000495]\n",
      " [0.50002   ]\n",
      " [0.50000244]\n",
      " [0.49999985]\n",
      " [0.5000008 ]\n",
      " [0.50000316]\n",
      " [0.5000023 ]\n",
      " [0.50000846]\n",
      " [0.5000151 ]\n",
      " [0.5000018 ]\n",
      " [0.5000089 ]\n",
      " [0.5000033 ]\n",
      " [0.50002223]\n",
      " [0.5000184 ]\n",
      " [0.5000081 ]\n",
      " [0.500006  ]\n",
      " [0.50000423]\n",
      " [0.5000115 ]\n",
      " [0.50000185]\n",
      " [0.50000787]\n",
      " [0.5000135 ]\n",
      " [0.50000626]\n",
      " [0.50000256]\n",
      " [0.4999999 ]\n",
      " [0.5000021 ]\n",
      " [0.50000334]\n",
      " [0.5000013 ]\n",
      " [0.50001746]\n",
      " [0.5000027 ]\n",
      " [0.5000045 ]\n",
      " [0.50000185]\n",
      " [0.5000042 ]\n",
      " [0.50000054]\n",
      " [0.50000614]\n",
      " [0.50000465]\n",
      " [0.5000042 ]\n",
      " [0.5000121 ]\n",
      " [0.5000216 ]\n",
      " [0.5000054 ]\n",
      " [0.500003  ]\n",
      " [0.5000017 ]\n",
      " [0.5000031 ]\n",
      " [0.50001305]\n",
      " [0.5000046 ]\n",
      " [0.50000226]\n",
      " [0.50001806]\n",
      " [0.5000018 ]\n",
      " [0.5000039 ]\n",
      " [0.5000042 ]\n",
      " [0.50000143]\n",
      " [0.50000674]\n",
      " [0.50001377]\n",
      " [0.50001526]\n",
      " [0.5000033 ]\n",
      " [0.5000073 ]\n",
      " [0.5000097 ]\n",
      " [0.5000029 ]\n",
      " [0.50001055]\n",
      " [0.50001764]\n",
      " [0.50001127]\n",
      " [0.5000028 ]\n",
      " [0.50000507]\n",
      " [0.50000423]\n",
      " [0.50001997]\n",
      " [0.50000805]\n",
      " [0.500009  ]\n",
      " [0.50001115]\n",
      " [0.5000028 ]\n",
      " [0.5000027 ]\n",
      " [0.5000079 ]\n",
      " [0.50000316]\n",
      " [0.5000155 ]\n",
      " [0.50001574]\n",
      " [0.5000047 ]\n",
      " [0.50000113]\n",
      " [0.50000423]\n",
      " [0.5000134 ]\n",
      " [0.5000041 ]\n",
      " [0.50002223]\n",
      " [0.5000085 ]\n",
      " [0.50000775]\n",
      " [0.500005  ]\n",
      " [0.50000507]\n",
      " [0.5000066 ]\n",
      " [0.5000097 ]\n",
      " [0.5000029 ]\n",
      " [0.5000033 ]\n",
      " [0.50000316]\n",
      " [0.5000108 ]\n",
      " [0.5000088 ]\n",
      " [0.5000014 ]\n",
      " [0.5000027 ]\n",
      " [0.50000346]\n",
      " [0.50000423]\n",
      " [0.5000024 ]\n",
      " [0.5000195 ]\n",
      " [0.5000064 ]\n",
      " [0.5000117 ]\n",
      " [0.5000064 ]\n",
      " [0.5000152 ]\n",
      " [0.5000101 ]\n",
      " [0.5000027 ]\n",
      " [0.5000019 ]\n",
      " [0.5000082 ]\n",
      " [0.50001127]\n",
      " [0.5000096 ]\n",
      " [0.5000087 ]\n",
      " [0.50000507]\n",
      " [0.50001144]\n",
      " [0.50001734]\n",
      " [0.5000052 ]\n",
      " [0.500006  ]\n",
      " [0.50000244]\n",
      " [0.5000064 ]\n",
      " [0.50000316]\n",
      " [0.5000009 ]\n",
      " [0.5000033 ]\n",
      " [0.500008  ]\n",
      " [0.50000185]\n",
      " [0.50000995]\n",
      " [0.50001913]\n",
      " [0.5000072 ]\n",
      " [0.500012  ]\n",
      " [0.50000435]\n",
      " [0.50000423]\n",
      " [0.5000065 ]\n",
      " [0.5000039 ]\n",
      " [0.5000028 ]\n",
      " [0.5000175 ]\n",
      " [0.5000016 ]\n",
      " [0.50000495]\n",
      " [0.5000108 ]\n",
      " [0.5000032 ]\n",
      " [0.50000185]\n",
      " [0.50001687]\n",
      " [0.5000102 ]\n",
      " [0.5000118 ]\n",
      " [0.50000674]\n",
      " [0.5000047 ]\n",
      " [0.5000048 ]\n",
      " [0.5000059 ]\n",
      " [0.5000097 ]\n",
      " [0.5000179 ]\n",
      " [0.50001   ]\n",
      " [0.5000003 ]\n",
      " [0.5000163 ]\n",
      " [0.50001836]\n",
      " [0.5000028 ]\n",
      " [0.5000013 ]\n",
      " [0.50000274]\n",
      " [0.5000101 ]\n",
      " [0.5000075 ]\n",
      " [0.50000685]\n",
      " [0.50000453]\n",
      " [0.5000077 ]\n",
      " [0.5000028 ]\n",
      " [0.5000071 ]\n",
      " [0.5000097 ]\n",
      " [0.5000267 ]\n",
      " [0.50000936]\n",
      " [0.500001  ]\n",
      " [0.5000029 ]\n",
      " [0.5000083 ]\n",
      " [0.5000022 ]\n",
      " [0.5000076 ]\n",
      " [0.50000244]\n",
      " [0.5000164 ]\n",
      " [0.5000033 ]\n",
      " [0.5000107 ]\n",
      " [0.5000084 ]\n",
      " [0.500004  ]\n",
      " [0.5000028 ]\n",
      " [0.5000179 ]\n",
      " [0.500002  ]\n",
      " [0.50000614]\n",
      " [0.50000423]\n",
      " [0.5000048 ]\n",
      " [0.5000035 ]\n",
      " [0.50000185]\n",
      " [0.50000733]\n",
      " [0.50001526]\n",
      " [0.50000876]\n",
      " [0.50001436]\n",
      " [0.5000001 ]\n",
      " [0.49999908]\n",
      " [0.5000154 ]\n",
      " [0.5000135 ]\n",
      " [0.5000062 ]\n",
      " [0.50001925]\n",
      " [0.5000048 ]\n",
      " [0.5000027 ]\n",
      " [0.50000596]\n",
      " [0.5000034 ]\n",
      " [0.5000089 ]\n",
      " [0.50000393]\n",
      " [0.50001234]\n",
      " [0.5000095 ]\n",
      " [0.5000047 ]\n",
      " [0.5000033 ]\n",
      " [0.5000029 ]\n",
      " [0.5000024 ]\n",
      " [0.500002  ]\n",
      " [0.5000028 ]\n",
      " [0.5000122 ]\n",
      " [0.5000033 ]\n",
      " [0.500004  ]\n",
      " [0.50000584]\n",
      " [0.50001717]\n",
      " [0.500004  ]\n",
      " [0.50000244]\n",
      " [0.5000054 ]\n",
      " [0.5000066 ]\n",
      " [0.50000244]\n",
      " [0.5000157 ]\n",
      " [0.50000304]\n",
      " [0.49999884]\n",
      " [0.5000047 ]\n",
      " [0.50000864]\n",
      " [0.5000033 ]\n",
      " [0.50000036]\n",
      " [0.5000012 ]\n",
      " [0.5000023 ]\n",
      " [0.5000057 ]\n",
      " [0.50001645]\n",
      " [0.5000071 ]\n",
      " [0.49999836]\n",
      " [0.49999937]\n",
      " [0.5000091 ]\n",
      " [0.5000089 ]\n",
      " [0.500017  ]\n",
      " [0.50002176]\n",
      " [0.50000757]\n",
      " [0.4999983 ]\n",
      " [0.50000566]\n",
      " [0.5000033 ]\n",
      " [0.50001353]\n",
      " [0.500006  ]\n",
      " [0.49999493]\n",
      " [0.5000096 ]\n",
      " [0.50000495]\n",
      " [0.5000069 ]\n",
      " [0.50000584]\n",
      " [0.5000043 ]\n",
      " [0.5000203 ]\n",
      " [0.5000052 ]\n",
      " [0.5000104 ]\n",
      " [0.5000022 ]\n",
      " [0.50000376]\n",
      " [0.50000185]\n",
      " [0.50000554]\n",
      " [0.5000035 ]\n",
      " [0.5000032 ]\n",
      " [0.50000566]\n",
      " [0.5000035 ]\n",
      " [0.50000334]\n",
      " [0.50000036]\n",
      " [0.5000017 ]\n",
      " [0.5000046 ]\n",
      " [0.50000566]\n",
      " [0.5000039 ]\n",
      " [0.5000209 ]\n",
      " [0.5000048 ]\n",
      " [0.49999955]\n",
      " [0.50001407]\n",
      " [0.5000165 ]\n",
      " [0.50000125]\n",
      " [0.5000063 ]\n",
      " [0.500001  ]\n",
      " [0.5000136 ]\n",
      " [0.5000034 ]\n",
      " [0.50000566]\n",
      " [0.50000376]\n",
      " [0.5000022 ]\n",
      " [0.50000405]\n",
      " [0.50000554]\n",
      " [0.50001353]\n",
      " [0.50001115]\n",
      " [0.5000064 ]\n",
      " [0.50000197]\n",
      " [0.50000423]\n",
      " [0.5000033 ]\n",
      " [0.50000197]\n",
      " [0.5000058 ]\n",
      " [0.50000906]\n",
      " [0.50000733]\n",
      " [0.50001067]\n",
      " [0.500019  ]\n",
      " [0.50000435]\n",
      " [0.5000066 ]\n",
      " [0.5000057 ]\n",
      " [0.5000077 ]\n",
      " [0.5000032 ]\n",
      " [0.5000031 ]\n",
      " [0.5000187 ]\n",
      " [0.5000096 ]\n",
      " [0.50001496]\n",
      " [0.5000029 ]\n",
      " [0.5000044 ]\n",
      " [0.5000038 ]\n",
      " [0.5000048 ]\n",
      " [0.5000163 ]\n",
      " [0.50000626]\n",
      " [0.50000334]\n",
      " [0.5000099 ]\n",
      " [0.5000028 ]\n",
      " [0.5000022 ]\n",
      " [0.500001  ]\n",
      " [0.50000435]\n",
      " [0.5000108 ]\n",
      " [0.5000036 ]\n",
      " [0.50001675]\n",
      " [0.5000027 ]\n",
      " [0.5000072 ]\n",
      " [0.5000047 ]\n",
      " [0.50000554]\n",
      " [0.5000114 ]\n",
      " [0.49999967]\n",
      " [0.5000102 ]\n",
      " [0.50000703]\n",
      " [0.50001794]\n",
      " [0.5000053 ]\n",
      " [0.50000185]\n",
      " [0.5000147 ]\n",
      " [0.5000226 ]\n",
      " [0.5000019 ]\n",
      " [0.5000017 ]\n",
      " [0.50001615]\n",
      " [0.50001687]\n",
      " [0.50000024]\n",
      " [0.50000274]\n",
      " [0.5000042 ]\n",
      " [0.50000817]\n",
      " [0.50000817]\n",
      " [0.5000047 ]\n",
      " [0.5000134 ]\n",
      " [0.50001633]\n",
      " [0.5000219 ]\n",
      " [0.50000757]\n",
      " [0.50000465]\n",
      " [0.50000376]\n",
      " [0.50000256]\n",
      " [0.5000065 ]\n",
      " [0.50000453]\n",
      " [0.5000177 ]\n",
      " [0.5000036 ]\n",
      " [0.5000128 ]\n",
      " [0.5000172 ]\n",
      " [0.5000075 ]\n",
      " [0.5000178 ]\n",
      " [0.5000027 ]\n",
      " [0.5000059 ]\n",
      " [0.5000039 ]\n",
      " [0.5000035 ]\n",
      " [0.50000274]\n",
      " [0.5000038 ]\n",
      " [0.5000121 ]\n",
      " [0.5000193 ]\n",
      " [0.5000127 ]\n",
      " [0.5000033 ]\n",
      " [0.5000081 ]\n",
      " [0.50001913]\n",
      " [0.5000016 ]\n",
      " [0.5000017 ]\n",
      " [0.5000026 ]\n",
      " [0.5000059 ]\n",
      " [0.50001067]\n",
      " [0.500009  ]\n",
      " [0.50001127]\n",
      " [0.50000745]\n",
      " [0.50001234]\n",
      " [0.50000006]\n",
      " [0.50001127]\n",
      " [0.50001085]\n",
      " [0.5000065 ]\n",
      " [0.50000894]\n",
      " [0.500007  ]\n",
      " [0.5000059 ]\n",
      " [0.5000046 ]\n",
      " [0.5000046 ]\n",
      " [0.5000065 ]\n",
      " [0.5000077 ]\n",
      " [0.5000022 ]\n",
      " [0.5000028 ]\n",
      " [0.50000817]\n",
      " [0.5000047 ]\n",
      " [0.50000244]\n",
      " [0.5000078 ]\n",
      " [0.50000376]\n",
      " [0.50001425]\n",
      " [0.50001144]\n",
      " [0.5000115 ]\n",
      " [0.5000042 ]\n",
      " [0.5000033 ]\n",
      " [0.5000089 ]\n",
      " [0.5000048 ]\n",
      " [0.5000014 ]\n",
      " [0.5000027 ]\n",
      " [0.50000995]\n",
      " [0.5000021 ]\n",
      " [0.5000121 ]\n",
      " [0.5000124 ]\n",
      " [0.50000095]\n",
      " [0.50000423]\n",
      " [0.5000134 ]\n",
      " [0.500012  ]\n",
      " [0.50000006]\n",
      " [0.5000043 ]\n",
      " [0.50000507]\n",
      " [0.50000435]\n",
      " [0.5000106 ]\n",
      " [0.5000016 ]\n",
      " [0.5000213 ]\n",
      " [0.50000465]\n",
      " [0.50000435]\n",
      " [0.500004  ]\n",
      " [0.50002724]\n",
      " [0.500006  ]\n",
      " [0.50001615]\n",
      " [0.50000435]\n",
      " [0.5000024 ]\n",
      " [0.5000088 ]\n",
      " [0.50000244]\n",
      " [0.5000029 ]\n",
      " [0.50000423]\n",
      " [0.50000304]\n",
      " [0.5000047 ]\n",
      " [0.5000089 ]\n",
      " [0.5000066 ]\n",
      " [0.50000006]\n",
      " [0.50000453]\n",
      " [0.5000069 ]\n",
      " [0.50001806]\n",
      " [0.5000039 ]\n",
      " [0.5000035 ]\n",
      " [0.50001156]\n",
      " [0.50000197]\n",
      " [0.5000083 ]\n",
      " [0.5000224 ]\n",
      " [0.49999863]\n",
      " [0.5000213 ]\n",
      " [0.500004  ]\n",
      " [0.5000018 ]\n",
      " [0.500011  ]\n",
      " [0.5000132 ]\n",
      " [0.5000062 ]\n",
      " [0.50000757]\n",
      " [0.50000554]\n",
      " [0.50000334]\n",
      " [0.50000316]\n",
      " [0.5000113 ]\n",
      " [0.5000072 ]\n",
      " [0.5000153 ]\n",
      " [0.50000685]\n",
      " [0.50000536]\n",
      " [0.50001734]\n",
      " [0.5000037 ]\n",
      " [0.50002   ]\n",
      " [0.50001246]\n",
      " [0.50000376]\n",
      " [0.50000316]\n",
      " [0.50000155]\n",
      " [0.500018  ]\n",
      " [0.50000286]\n",
      " [0.5000172 ]\n",
      " [0.5000045 ]\n",
      " [0.50001436]\n",
      " [0.500009  ]\n",
      " [0.50001115]\n",
      " [0.5000061 ]\n",
      " [0.500007  ]\n",
      " [0.5000143 ]\n",
      " [0.50000864]\n",
      " [0.5000047 ]\n",
      " [0.50000495]\n",
      " [0.50001526]\n",
      " [0.50001454]\n",
      " [0.5000076 ]\n",
      " [0.50001526]\n",
      " [0.50000495]\n",
      " [0.5000022 ]\n",
      " [0.50000435]\n",
      " [0.50000256]]\n",
      "\n",
      "[[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "(800, 2)\n",
      "[[0.94590643 0.77046784]\n",
      " [0.64912281 0.45614035]\n",
      " [0.9619883  0.7997076 ]\n",
      " ...\n",
      " [0.93274854 0.76315789]\n",
      " [0.67251462 0.0877193 ]\n",
      " [0.9371345  0.74269006]]\n",
      "[[0.5000095  0.94590646 0.7704678 ]\n",
      " [0.5000029  0.64912283 0.45614034]\n",
      " [0.5000046  0.96198833 0.7997076 ]\n",
      " ...\n",
      " [0.5000022  0.93274856 0.7631579 ]\n",
      " [0.50000435 0.6725146  0.0877193 ]\n",
      " [0.50000256 0.9371345  0.7426901 ]]\n",
      "(800, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "print(X)\n",
    "trainAttrX = np.array(trainAttrX)\n",
    "trainAttrX.resize(800,2)\n",
    "newtrainy=np.array(newtrainy)\n",
    "newtrainy = newtrainy.reshape(-1,1)\n",
    "print()\n",
    "print(newtrainy)\n",
    "print(newtesty)\n",
    "print(trainAttrX.shape)\n",
    "print(trainAttrX)\n",
    "traindata = concatenate([X,trainAttrX])\n",
    "traindata = np.array(traindata)\n",
    "traindata.reshape(-1,1)\n",
    "print(traindata)\n",
    "print(traindata.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-29 21:47:34.950] Start to fit the model:\n",
      "[2023-12-29 21:47:34.951] Fitting cascade layer = 0 \n",
      "[2023-12-29 21:47:44.216] layer = 0  | Val Acc = 98.875 % | Elapsed = 9.265 s\n",
      "[2023-12-29 21:47:44.233] Fitting cascade layer = 1 \n",
      "[2023-12-29 21:47:55.598] layer = 1  | Val Acc = 98.875 % | Elapsed = 11.365 s\n",
      "[2023-12-29 21:47:55.598] Early stopping counter: 1 out of 2\n",
      "[2023-12-29 21:47:55.614] Fitting cascade layer = 2 \n",
      "[2023-12-29 21:48:06.197] layer = 2  | Val Acc = 98.750 % | Elapsed = 10.583 s\n",
      "[2023-12-29 21:48:06.197] Early stopping counter: 2 out of 2\n",
      "[2023-12-29 21:48:06.197] Handling early stopping\n",
      "[2023-12-29 21:48:06.197] The optimal number of layers: 1\n"
     ]
    }
   ],
   "source": [
    "model = CascadeForestClassifier(n_estimators=50,random_state=1)\n",
    "hist = model.fit(traindata,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.PNG\n",
      "002.PNG\n",
      "003.PNG\n",
      "004.PNG\n",
      "005.PNG\n",
      "006.PNG\n",
      "007.PNG\n",
      "008.PNG\n",
      "009.PNG\n",
      "010.PNG\n",
      "011.PNG\n",
      "012.PNG\n",
      "013.PNG\n",
      "014.PNG\n",
      "015.PNG\n",
      "016.PNG\n",
      "017.PNG\n",
      "018.PNG\n",
      "019.PNG\n",
      "020.PNG\n",
      "021.PNG\n",
      "022.PNG\n",
      "023.PNG\n",
      "024.PNG\n",
      "025.PNG\n",
      "026.PNG\n",
      "027.PNG\n",
      "028.PNG\n",
      "029.PNG\n",
      "030.PNG\n",
      "031.PNG\n",
      "032.PNG\n",
      "033.PNG\n",
      "034.PNG\n",
      "035.PNG\n",
      "036.PNG\n",
      "037.PNG\n",
      "038.PNG\n",
      "039.PNG\n",
      "040.PNG\n",
      "041.PNG\n",
      "042.PNG\n",
      "043.PNG\n",
      "044.PNG\n",
      "045.PNG\n",
      "046.PNG\n",
      "047.PNG\n",
      "048.PNG\n",
      "049.PNG\n",
      "050.PNG\n",
      "051.PNG\n",
      "052.PNG\n",
      "053.PNG\n",
      "054.PNG\n",
      "055.PNG\n",
      "056.PNG\n",
      "057.PNG\n",
      "058.PNG\n",
      "059.PNG\n",
      "060.PNG\n",
      "061.PNG\n",
      "062.PNG\n",
      "063.PNG\n",
      "064.PNG\n",
      "065.PNG\n",
      "066.PNG\n",
      "067.PNG\n",
      "068.PNG\n",
      "069.PNG\n",
      "070.PNG\n",
      "071.PNG\n",
      "072.PNG\n",
      "073.PNG\n",
      "074.PNG\n",
      "075.PNG\n",
      "076.PNG\n",
      "077.PNG\n",
      "078.PNG\n",
      "079.PNG\n",
      "080.PNG\n",
      "081.PNG\n",
      "082.PNG\n",
      "083.PNG\n",
      "084.PNG\n",
      "085.PNG\n",
      "086.PNG\n",
      "087.PNG\n",
      "088.PNG\n",
      "089.PNG\n",
      "090.PNG\n",
      "091.PNG\n",
      "092.PNG\n",
      "093.PNG\n",
      "094.PNG\n",
      "095.PNG\n",
      "096.PNG\n",
      "097.PNG\n",
      "098.PNG\n",
      "099.PNG\n",
      "100.PNG\n",
      "101.PNG\n",
      "102.PNG\n",
      "103.PNG\n",
      "104.PNG\n",
      "105.PNG\n",
      "106.PNG\n",
      "107.PNG\n",
      "108.PNG\n",
      "109.PNG\n",
      "110.PNG\n",
      "111.PNG\n",
      "112.PNG\n",
      "113.PNG\n",
      "114.PNG\n",
      "115.PNG\n",
      "116.PNG\n",
      "117.PNG\n",
      "118.PNG\n",
      "119.PNG\n",
      "120.PNG\n",
      "121.PNG\n",
      "122.PNG\n",
      "123.PNG\n",
      "124.PNG\n",
      "125.PNG\n",
      "126.PNG\n",
      "127.PNG\n",
      "128.PNG\n",
      "129.PNG\n",
      "130.PNG\n",
      "131.PNG\n",
      "132.PNG\n",
      "133.PNG\n",
      "134.PNG\n",
      "135.PNG\n",
      "136.PNG\n",
      "137.PNG\n",
      "138.PNG\n",
      "139.PNG\n",
      "140.PNG\n",
      "141.PNG\n",
      "142.PNG\n",
      "143.PNG\n",
      "146.PNG\n",
      "148.PNG\n",
      "149.PNG\n",
      "152.PNG\n",
      "154.PNG\n",
      "155.PNG\n",
      "156.PNG\n",
      "157.PNG\n",
      "158.PNG\n",
      "160.PNG\n",
      "161.PNG\n",
      "164.PNG\n",
      "165.PNG\n",
      "180.PNG\n",
      "181.PNG\n",
      "182.PNG\n",
      "183.PNG\n",
      "184.PNG\n",
      "185.PNG\n",
      "186.PNG\n",
      "187.PNG\n",
      "188.PNG\n",
      "189.PNG\n",
      "190.PNG\n",
      "191.PNG\n",
      "192.PNG\n",
      "193.PNG\n",
      "194.PNG\n",
      "195.PNG\n",
      "196.PNG\n",
      "197.PNG\n",
      "198.PNG\n",
      "200.PNG\n",
      "(176, 320, 320, 9)\n"
     ]
    }
   ],
   "source": [
    "gasdata = pd.read_csv(\"/Users/eddie/Downloads/Gas Sensors Data - Sheet1 (3) (1).csv\")\n",
    "result = gasdata['Gas']\n",
    "gasdata = gasdata.drop(columns=['Gas'])\n",
    "gasdata= (gasdata - np.min(gasdata)) / (np.max(gasdata) - np.min(gasdata))\n",
    "images =  os.listdir(\"/Users/eddie/Downloads/No Gas 4/No Gas\")\n",
    "X_dat = []\n",
    "for image in images:\n",
    "       print(image)\n",
    "       img = mpimg.imread('/Users/eddie/Downloads/No Gas 4/No Gas/'+image)\n",
    "       img.resize(320,320,9)\n",
    "       img = img/255.0\n",
    "       X_dat.append(img)\n",
    "test_images = np.array(X_dat)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 451ms/step\n"
     ]
    }
   ],
   "source": [
    "#print(test_images.shape)\n",
    "cows = cnn.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 1)\n",
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "cows = np.array(cows)\n",
    "# print(cows)\n",
    "print(cows.shape)\n",
    "print(testAttrX.shape)\n",
    "# testAttrX.resize(122,2)\n",
    "# print(gasdata)\n",
    "# print(gasdata.shape)\n",
    "test = concatenate([cows,gasdata])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-29 21:49:45.869] Start to evalute the model:\n",
      "[2023-12-29 21:49:45.869] Evaluating cascade layer = 0 \n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy: 0.835227\n",
      "Precision: 0.761194\n",
      "Recall: 0.796875\n",
      "F1 score: 0.778626\n"
     ]
    }
   ],
   "source": [
    "performance = model.predict(test)\n",
    "print(performance)\n",
    "cows = np.array(testy)\n",
    "performance.round()\n",
    "actual = []\n",
    "for value in performance: \n",
    "    print(value)\n",
    "    if(value>=0.5):\n",
    "            actual.append(1)\n",
    "    else:\n",
    "            actual.append(0)\n",
    "\n",
    "acutal = np.array(actual)\n",
    "print(actual)\n",
    "testy = result\n",
    "testy = np.array(testy)\n",
    "with np.printoptions(threshold=np.inf):\n",
    "        print(testy)\n",
    "accuracy = accuracy_score(testy, actual)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "precision = precision_score(testy, actual)\n",
    "print('Precision: %f' % precision)\n",
    "recall = recall_score(testy, actual)\n",
    "print('Recall: %f' % recall)\n",
    "f1 = f1_score(testy, actual)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newtrainy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnewtrainy\u001b[49m)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m create_cnn()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#model.load('/Users/Eddie/Downloads/alexnet')\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'newtrainy' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
  },
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
