{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyexpat import model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import locale\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import preprocessing\n",
    "import locale\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from deepforest import CascadeForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,input_shape = (320,320,9), kernel_size = (7,7), strides = 2, padding = 'valid', activation = 'relu'))\n",
    "    model.add(AveragePooling2D(pool_size = 2))\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), strides  = 1, activation = 'relu', padding  = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, kernel_size = (1,1), strides  = 1, activation = 'relu', padding  = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(128, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides = 1, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, kernel_size=(1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1024, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 2, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size=(1,1),strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512,kernel_size = (3,3), strides = 1,activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2048, kernel_size = (1,1), strides = 1, activation = 'relu', padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D(pool_size = 2, padding = 'same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gasdata = pd.read_csv(\"/Users/Eddie/Downloads/data5.csv\")\n",
    "data_dir = '/Users/Eddie/Downloads/Data5'\n",
    "imagedata = sorted(os.listdir(data_dir))\n",
    "print(len(imagedata))\n",
    "X_data = []\n",
    "for image in imagedata:\n",
    "        print(image)\n",
    "        img = mpimg.imread('/Users/Eddie/Downloads/Data5/'+image)\n",
    "        img = img.reshape(320,320,9)\n",
    "        img = img/255.0\n",
    "        X_data.append(img)\n",
    "images = np.array(X_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MQ2       MQ7\n",
      "868  0.958944  0.794721\n",
      "739  0.945748  0.810850\n",
      "744  0.944282  0.806452\n",
      "368  0.885630  0.651026\n",
      "651  0.868035  0.806452\n",
      "..        ...       ...\n",
      "337  0.598240  0.469208\n",
      "917  0.976540  0.824047\n",
      "556  0.680352  0.256598\n",
      "341  0.646628  0.464809\n",
      "798  0.948680  0.809384\n",
      "\n",
      "[800 rows x 2 columns]\n",
      "          MQ2       MQ7\n",
      "65   0.887427  0.666667\n",
      "298  0.593567  0.448830\n",
      "458  0.652047  0.459064\n",
      "493  0.836257  0.605263\n",
      "155  0.812865  0.627193\n",
      "..        ...       ...\n",
      "448  0.659357  0.469298\n",
      "67   0.878655  0.659357\n",
      "303  0.657895  0.500000\n",
      "276  0.713450  0.546784\n",
      "494  0.839181  0.631579\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "868    1\n",
      "739    1\n",
      "744    1\n",
      "368    0\n",
      "651    1\n",
      "      ..\n",
      "337    0\n",
      "917    1\n",
      "556    1\n",
      "341    0\n",
      "798    1\n",
      "Name: Gas, Length: 800, dtype: int64\n",
      "65     0\n",
      "298    0\n",
      "458    0\n",
      "493    0\n",
      "155    0\n",
      "      ..\n",
      "448    0\n",
      "67     0\n",
      "303    0\n",
      "276    0\n",
      "494    0\n",
      "Name: Gas, Length: 200, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "split = train_test_split(gasdata, images, test_size=0.2)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
    "trainy = trainAttrX[\"Gas\"]\n",
    "testy = testAttrX[\"Gas\"]\n",
    "trainAttrX = trainAttrX.drop(columns=['Gas'])\n",
    "testAttrX = testAttrX.drop(columns = ['Gas'])\n",
    "trainAttrX= (trainAttrX - np.min(trainAttrX)) / (np.max(trainAttrX) - np.min(trainAttrX))\n",
    "testAttrX = (testAttrX - np.min(testAttrX)) / (np.max(testAttrX) - np.min(testAttrX))\n",
    "print(trainAttrX)\n",
    "print(testAttrX)\n",
    "print(trainy)\n",
    "print(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65     0\n",
      "298    0\n",
      "458    0\n",
      "493    0\n",
      "155    0\n",
      "      ..\n",
      "448    0\n",
      "67     0\n",
      "303    0\n",
      "276    0\n",
      "494    0\n",
      "Name: Gas, Length: 200, dtype: int64\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(testy)\n",
    "newtesty = []\n",
    "for value in testy:\n",
    "    value = float(value)\n",
    "    newtesty.append(value)\n",
    "print(newtesty)\n",
    "newtrainy = []\n",
    "for value in trainy:\n",
    "    value = float(value)\n",
    "    newtrainy.append(value)\n",
    "\n",
    "print(newtrainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 26s 969ms/step\n",
      "(800, 2048)\n"
     ]
    }
   ],
   "source": [
    "cnn = create_cnn()\n",
    "X = cnn.predict(trainImagesX)\n",
    "print(X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "print(X)\n",
    "trainAttrX = np.array(trainAttrX)\n",
    "trainAttrX.resize(800,9216)\n",
    "newtrainy=np.array(newtrainy)\n",
    "newtrainy = newtrainy.reshape(-1,1)\n",
    "print()\n",
    "print(newtrainy)\n",
    "print(newtesty)\n",
    "print(trainAttrX.shape)\n",
    "print(trainAttrX)\n",
    "traindata = concatenate([X,trainAttrX])\n",
    "traindata = np.array(traindata)\n",
    "traindata.reshape(-1,1)\n",
    "print(traindata)\n",
    "print(traindata.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-30 01:53:30.795] Start to fit the model:\n",
      "[2023-11-30 01:53:30.795] Fitting cascade layer = 0 \n",
      "[2023-11-30 01:57:02.654] layer = 0  | Val Acc = 80.375 % | Elapsed = 211.858 s\n",
      "[2023-11-30 01:57:02.803] Fitting cascade layer = 1 \n",
      "[2023-11-30 01:58:06.639] layer = 1  | Val Acc = 83.500 % | Elapsed = 63.836 s\n",
      "[2023-11-30 01:58:06.770] Fitting cascade layer = 2 \n",
      "[2023-11-30 01:59:09.419] layer = 2  | Val Acc = 83.875 % | Elapsed = 62.649 s\n",
      "[2023-11-30 01:59:09.550] Fitting cascade layer = 3 \n",
      "[2023-11-30 02:00:16.150] layer = 3  | Val Acc = 83.375 % | Elapsed = 66.600 s\n",
      "[2023-11-30 02:00:16.150] Early stopping counter: 1 out of 2\n",
      "[2023-11-30 02:00:16.283] Fitting cascade layer = 4 \n",
      "[2023-11-30 02:01:22.801] layer = 4  | Val Acc = 83.250 % | Elapsed = 66.519 s\n",
      "[2023-11-30 02:01:22.801] Early stopping counter: 2 out of 2\n",
      "[2023-11-30 02:01:22.801] Handling early stopping\n",
      "[2023-11-30 02:01:22.805] The optimal number of layers: 3\n"
     ]
    }
   ],
   "source": [
    "model = CascadeForestClassifier(n_estimators=50,random_state=1)\n",
    "model.fit(traindata,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 24s 946ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\eddie\\a\\resnet.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eddie/a/resnet.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cnnpred \u001b[39m=\u001b[39m cnn\u001b[39m.\u001b[39mpredict(trainImagesX)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/eddie/a/resnet.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mpredict()\n",
      "\u001b[1;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "cnnpred = cnn.predict(trainImagesX)\n",
    "model.predict()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
  },
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
